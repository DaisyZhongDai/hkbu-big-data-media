{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypage_sale_name=mypage_sale1.find_all('a',attrs={'class':'posLink'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.append(mypage_sale_name[i].attrs['href'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p17417864/Desktop/venv/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "def sale_page_1(urls):\n",
    "    r=requests.get(\n",
    "        urls,\n",
    "        headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "        }\n",
    "    )\n",
    "    mypage_sale1=BeautifulSoup(r.text)\n",
    "    mypage_sale_name=mypage_sale1.find_all('a',attrs={'class':'posLink'})\n",
    "    mypage_sale_location=mypage_sale1.find_all('p',attrs={'class':'job-location'})\n",
    "    a=[]\n",
    "    for i in range(0,len(mypage_sale_name)):\n",
    "        a.append(mypage_sale_name[i].text.strip())\n",
    "\n",
    "    b=[]\n",
    "    for i in range(0,len(mypage_sale_location)):\n",
    "        b.append(mypage_sale_location[i].text.strip())\n",
    "\n",
    "    c=[]\n",
    "    for i in range(0,len(mypage_sale_name)):\n",
    "        c.append(mypage_sale_name[i].attrs['href'])    \n",
    "\n",
    "    degree=[]\n",
    "    salary=[]\n",
    "    for i in c:\n",
    "        c1=requests.get(i,headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'})\n",
    "        c2=BeautifulSoup(c1.text)  \n",
    "        degree1=c2.find('p',attrs={'class':'meta-item primary-meta-edu col-xs-9'})\n",
    "        if degree1 is None:\n",
    "            degree.append('null')\n",
    "        else:\n",
    "            degree.append(degree1.text.strip())\n",
    "\n",
    "        salary1=c2.find('p',attrs={'class':'meta-item primary-meta-salary col-xs-9'})\n",
    "        if salary1 is None:\n",
    "            salary.append('null')\n",
    "        else:\n",
    "            salary.append(salary1.text.strip())\n",
    "\n",
    "    salepage=[]\n",
    "    for i in range(0,len(mypage_sale_name)):\n",
    "        salepage.append([a[i],b[i],c[i],degree[i],salary[i]])\n",
    "        \n",
    "    return salepage\n",
    "\n",
    "#get recruitment information of sales-related jobs on JobsDB.com\n",
    "sale_page_all=[]\n",
    "for i in range(1,265):\n",
    "    url='https://hk.jobsdb.com/hk/jobs/sales-cs-business-devpt/'+str(i)\n",
    "    sale_page_all.extend(sale_page_1(url))\n",
    "sale_page_all\n",
    "\n",
    "with open('sale_page_all.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerows(sale_page_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p17417864/Desktop/venv/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "def hr_page_1(urlss):\n",
    "    rhr=requests.get(\n",
    "        urlss,\n",
    "        headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "        }\n",
    "    )\n",
    "    mypage_hr1=BeautifulSoup(rhr.text)\n",
    "    mypage_hr_name=mypage_hr1.find_all('a',attrs={'class':'posLink'})\n",
    "    mypage_hr_location=mypage_hr1.find_all('p',attrs={'class':'job-location'})\n",
    "    ahr=[]\n",
    "    for i in range(0,len(mypage_hr_name)):\n",
    "        ahr.append(mypage_hr_name[i].text.strip())\n",
    "\n",
    "    bhr=[]\n",
    "    for i in range(0,len(mypage_hr_location)):\n",
    "        bhr.append(mypage_hr_location[i].text.strip())\n",
    "\n",
    "    c_hr=[]\n",
    "    for i in range(0,len(mypage_hr_name)):\n",
    "        c_hr.append(mypage_hr_name[i].attrs['href'])    \n",
    "\n",
    "    degreehr=[]\n",
    "    salaryhr=[]\n",
    "    for i in c_hr:\n",
    "        c1hr=requests.get(i,headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'})\n",
    "        c2hr=BeautifulSoup(c1hr.text)  \n",
    "        degree1hr=c2hr.find('p',attrs={'class':'meta-item primary-meta-edu col-xs-9'})\n",
    "        if degree1hr is None:\n",
    "            degreehr.append('null')\n",
    "        else:\n",
    "            degreehr.append(degree1hr.text.strip())\n",
    "\n",
    "        salary1hr=c2hr.find('p',attrs={'class':'meta-item primary-meta-salary col-xs-9'})\n",
    "        if salary1hr is None:\n",
    "            salaryhr.append('null')\n",
    "        else:\n",
    "            salaryhr.append(salary1hr.text.strip())\n",
    "\n",
    "\n",
    "    hrpage=[]\n",
    "    for i in range(0,len(mypage_hr_name)):\n",
    "        hrpage.append([ahr[i],bhr[i],c_hr[i],degreehr[i],salaryhr[i]])\n",
    "        \n",
    "    return hrpage\n",
    "\n",
    "#get recruitment information of hr-related jobs on JobsDB.com\n",
    "hr_page_all=[]\n",
    "for i in range(1,202):\n",
    "    url='https://hk.jobsdb.com/hk/jobs/admin-hr/'+str(i)\n",
    "    hr_page_all.extend(hr_page_1(url))\n",
    "\n",
    "with open('hr_page_all.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                        quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerows(hr_page_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p17417864/Desktop/venv/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get recruitment information of finance-related jobs on JobsDB.com\n",
    "\n",
    "finance_page_all=[]\n",
    "for i in range(1,166):\n",
    "    url='https://hk.jobsdb.com/hk/jobs/finance-banking/'+str(i)\n",
    "    finance_page_all.extend(hr_page_1(url))\n",
    "    \n",
    "\n",
    "with open('finance_page_all.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                        quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerows(finance_page_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p17417864/Desktop/venv/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#get recruitment information of IT-related jobs on JobsDB.com\n",
    "it_page_all=[]\n",
    "for i in range(1,158):\n",
    "    url='https://hk.jobsdb.com/hk/jobs/information-technology/'+str(i)\n",
    "    it_page_all.extend(hr_page_1(url))\n",
    "    \n",
    "\n",
    "with open('it_page_all.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                        quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerows(it_page_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p17417864/Desktop/venv/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#get recruitment information of accounting-related jobs on JobsDB.com\n",
    "accounting_page_all=[]\n",
    "for i in range(1,155):\n",
    "    url='https://hk.jobsdb.com/hk/jobs/accounting/'+str(i)\n",
    "    accounting_page_all.extend(hr_page_1(url))\n",
    "    \n",
    "\n",
    "with open('accounting_page_all.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                        quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerows(accounting_page_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
